  // Copyright (C) 2015 Technische Universitaet Muenchen
// This file is part of the Mamico project. For conditions of distribution
// and use, please see the copyright notice in Mamico's main folder, or at
// www5.in.tum.de/mamico

template<unsigned int dim>
tarch::utils::MultiMDService<dim>::MultiMDService(const tarch::la::Vector<dim,unsigned int> &numberProcessesPerMDSimulation, const unsigned int &totalNumberMDSimulations):
// initialise all values, either immediately consistent for single and parallel mode, or for single mode only (and overwrite the setting afterwards in constructor body)
_numberProcessesPerMDSimulation(numberProcessesPerMDSimulation),
_numberLocalComms(1),
_totalNumberMDSimulations(totalNumberMDSimulations),
_avgNumberMDSimulationsPerLocalComm(totalNumberMDSimulations),
_thisNumberMDSimulations(totalNumberMDSimulations),
_globalSize(1), _globalRank(0),
_localSize(1),_localRank(0),
_numberActiveProcesses(1), _globalActiveRank(0),
_activeProcesses(){
#if (TARCH_PARALLEL==TARCH_YES)
  MPI_Comm_size(MPI_COMM_WORLD,&_globalSize);
  MPI_Comm_rank(MPI_COMM_WORLD,&_globalRank);

  // test process distribution
  _localSize = numberProcessesPerMDSimulation[0];
  for (unsigned int d = 1; d<dim; d++){ _localSize *= numberProcessesPerMDSimulation[d]; }
  if (_globalSize%_localSize!=0){
    std::cout << "_globalSize = " << _globalSize << std::endl;
    std::cout << "_localSize = " << _localSize << std::endl;
    std::cout << "ERROR MultiMDService::MultiMDService(): _globalSize mod _localSize!=0 !" << std::endl;
    std::cout << "The number of globally available MPI processes must be filled completely with local MD simulation processes!" << std::endl; exit(EXIT_FAILURE);
  }

  // compute number of local communicators
  _numberLocalComms = _globalSize/_localSize;
  // initialise local communicator by splitting the whole process domain into _numberLocalComms communicators
  MPI_Comm_split(MPI_COMM_WORLD,_globalRank/_localSize,_globalRank,&_localComm);
  // initialise local rank
  MPI_Comm_rank(_localComm,&_localRank);
  // compute avg number of MD simulations per local communicator
  _avgNumberMDSimulationsPerLocalComm = _totalNumberMDSimulations/_numberLocalComms;
  // compute the number of MD simulations on the current communicator. This is always the same as _avgMDSimulations..., except for the last communicator which is filled up with the rest
  if ((unsigned int)(_globalRank/_localSize+1)==_numberLocalComms){
    _thisNumberMDSimulations = _totalNumberMDSimulations - _avgNumberMDSimulationsPerLocalComm*(_numberLocalComms-1);
  } else {
    _thisNumberMDSimulations = _avgNumberMDSimulationsPerLocalComm;
  }

  _activeProcesses = std::vector<bool>(_globalSize, 1);

  _numberActiveProcesses = std::accumulate(_activeProcesses.begin(), _activeProcesses.end(), 0);
  
  computeGlobalActiveRanks();

  _avgNumberMDSimulationsPerLocalComm = _totalNumberMDSimulations/_numberLocalComms;

  
#endif
}


template<unsigned int dim>
tarch::utils::MultiMDService<dim>::~MultiMDService(){}


template<unsigned int dim>
unsigned int tarch::utils::MultiMDService<dim>::getGlobalNumberOfLocalMDSimulation(unsigned int localMDSimulation) const {
  return (_globalRank/_localSize)*_avgNumberMDSimulationsPerLocalComm + localMDSimulation;
}

template<unsigned int dim>
int tarch::utils::MultiMDService<dim>::getLocalNumberOfGlobalMDSimulation(unsigned int globalMDSimulation) const {
  return globalMDSimulation - (_globalRank/_localSize) * _avgNumberMDSimulationsPerLocalComm; 
}

template<unsigned int dim>
void tarch::utils::MultiMDService<dim>::deactivateSimulation(const int &globalIndex) {
    if(_thisNumberMDSimulations > 0) {
      _thisNumberMDSimulations -= 1;

      if(_thisNumberMDSimulations == 0) {
        unsigned int iStart = globalIndex * _localSize; // Index of the first rank belonging to this simulation

        int counter = 0;
        for(unsigned int i=iStart;i<iStart + _localSize;++i) { counter += _activeProcesses[i] ? 1 : 0; }

        if (counter == _localSize) {
          for(unsigned int i=iStart;i<iStart + _localSize;++i) {
            _activeProcesses[i] = false;
          }
          _numberActiveProcesses -= _localSize;
          computeGlobalActiveRanks();
        }
        else if (counter == 0) { 
          std::cout << "Simulation not active!" << std::endl;
        }
        else {
          std::cout << "ERROR tarch::utils::MultiMDService::deactivateSimulation: invalid number of active processes found for simulation " 
                    << globalIndex << ": " << counter << "!" << std::endl;
                    exit(EXIT_FAILURE);
        }
      }
    }
  }

  /* Compute the global rank considering only active processes
   * Inactive processes retrieve global active rank -1
   * Example: If process 0 is inactive, it is assigned -1 as rank.
   *          If, then, process 1 is active, is gets as rank 0.
   */
  template<unsigned int dim>
  void tarch::utils::MultiMDService<dim>::computeGlobalActiveRanks() {
#if TARCH_PARALLEL == TARCH_YES
    if(_globalRank == 0) {
      if(_activeProcesses[0] == 0) _globalActiveRank = -1;
      else _globalActiveRank = 0;
    }
    else {
      std::vector<int> partialSum(_globalSize, 0);
      for(int i=1;i<_globalSize;++i) {
        partialSum[i] = partialSum[i-1] + (_activeProcesses[i] ? 1 : 0);
      }
      
      if(partialSum[_globalRank] > partialSum[_globalRank-1]) {
        _globalActiveRank = partialSum[_globalRank];
      }
      else _globalActiveRank = -1;
    }
    #endif
  }


